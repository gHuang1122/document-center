# 一、背景

负载平衡（Load balancing）是一种计算机技术，用来在多个计算机（计算机集群）、网络连接、CPU、磁盘驱动器或其他资源中分配负载，以达到最优化资源使用、最大化吞吐率、最小化响应时间、同时避免过载的目的。 使用带有负载平衡的多个服务器组件，取代单一的组件，可以通过冗余提高可靠性。负载平衡服务通常是由专用软件和硬件来完成。 主要作用是将大量作业合理地分摊到多个操作单元上进行执行，用于解决互联网架构中的高并发和高可用的问题。

# 二、技术方案
## 2.1 Nginx 负载均衡

Nginx 是什么呢？Nginx 如何实现负载均衡？这就要从正向代理和反向代理说起了。

- **正向代理** 
    正向代理（Forward Proxy）最大的特点是，客户端非常明确要访问的服务器地址，它代理客户端，替客户端发出请求。比如：棵学上网，俗称 FQ（警告⚠️：FQ 操作违反相关法律规定，本文只是为了解释正向代理向读者举个例子，仅供学习参考，切勿盲目 FQ）。

    ![](https://cdn.nlark.com/yuque/0/2020/webp/2215478/1604575942443-ce94b26a-7561-4095-9275-c8970b43ce7e.webp#align=left&display=inline&height=368&margin=%5Bobject%20Object%5D&originHeight=368&originWidth=1106&size=0&status=done&style=none&width=1106)

    假设客户端想要访问 Google，它明确知道待访问的服务器地址是 [www.google.com/，但由于条件限制，它找…](https://www.google.com/%EF%BC%8C%E4%BD%86%E7%94%B1%E4%BA%8E%E6%9D%A1%E4%BB%B6%E9%99%90%E5%88%B6%EF%BC%8C%E5%AE%83%E6%89%BE%E6%9D%A5%E4%BA%86%E4%B8%80%E4%B8%AA%E8%83%BD%E5%A4%9F%E8%AE%BF%E9%97%AE%E5%88%B0) Google 的”朋友”：代理服务器。客户端把请求发给代理服务器，由代理服务器代替它请求 Google，最终再将响应返回给客户端。这便是一次正向代理的过程，该过程中服务器并不知道真正发出请求的是谁。

- **反向代理** 
    那么，随着请求量的爆发式增长，服务器觉得自己一个人始终是应付不过来，需要兄弟服务器们帮忙，于是它喊来了自己的兄弟以及代理服务器朋友。

    此时，来自不同客户端的所有请求实际上都发到了代理服务器处，再由代理服务器按照一定的规则将请求分发给各个服务器。

    这就是反向代理（Reverse Proxy），反向代理隐藏了服务器的信息，它代理的是服务器端，代其接收请求。换句话说，反向代理的过程中，客户端并不知道具体是哪台服务器处理了自己的请求。如此一来，既提高了访问速度，又为安全性提供了保证。

    ![](https://cdn.nlark.com/yuque/0/2020/webp/2215478/1604575942433-0bb90df0-71b9-4f9b-bd11-8ccf8bf0826f.webp#align=left&display=inline&height=602&margin=%5Bobject%20Object%5D&originHeight=602&originWidth=1062&size=0&status=done&style=none&width=1062)

    在这之中，反向代理需要考虑的问题是，如何进行均衡分工，控制流量，避免出现局部节点负载过大的问题。通俗的讲，就是如何为每台服务器合理的分配请求，使其整体具有更高的工作效率和资源利用率。

- **Nginx 是什么？** 

    Nginx 作为一个基于 C 实现的高性能 Web 服务器，可以通过系列算法解决上述的负载均衡问题。并且由于它具有高并发、高可靠性、高扩展性、开源等特点，成为开发人员常用的反向代理工具。

## 2.2 负载均衡常用算法

**1. 轮询 （round-robin）** 

轮询为负载均衡中较为基础也较为简单的算法，它不需要配置额外参数。假设配置文件中共有**M** 台服务器，该算法遍历服务器节点列表，并按节点次序每轮选择一台服务器处理请求。当所有节点均被调用过一次后，该算法将从第一个节点开始重新一轮遍历。

**特点** ：由于该算法中每个请求按时间顺序逐一分配到不同的服务器处理，因此适用于服务器性能相近的集群情况，其中每个服务器承载相同的负载。但对于服务器性能不同的集群而言，该算法容易引发资源分配不合理等问题。

**2. 加权轮询** 

为了避免普通轮询带来的弊端，加权轮询应运而生。在加权轮询中，每个服务器会有各自的 `weight`。一般情况下，`weight` 的值越大意味着该服务器的性能越好，可以承载更多的请求。该算法中，客户端的请求按权值比例分配，当一个请求到达时，优先为其分配权值最大的服务器。

**特点** ：加权轮询可以应用于服务器性能不等的集群中，使资源分配更加合理化。

Nginx 加权轮询源码可见：[ngx_http_upstream_round_robin.c](https://github.com/nginx/nginx/blob/master/src/http/ngx_http_upstream_round_robin.c)，源码分析可参考：[关于轮询策略原理的自我理解](https://blog.csdn.net/BlacksunAcheron/article/details/84439302)。其核心思想是，遍历各服务器节点，并计算节点权值，计算规则为 `current_weight` 与其对应的 `effective_weight` 之和，每轮遍历中选出权值最大的节点作为最优服务器节点。其中 `effective_weight` 会在算法的执行过程中随资源情况和响应情况而改变。较为核心的部分如下：

```
for (peer = rrp->peers->peer, i = 0;
	peer; 	/* peer 为当前遍历的服务器结点*/
  peer = peer->next, i++)
{
  ...
    
	/* 每轮遍历会更新 peer 当前的权值*/
	peer->current_weight += peer->effective_weight;
  ...
    
	/* best 为当前服务器中的最优节点，即本轮中选中的服务器节点*/
	if (best == NULL || peer->current_weight > best->current_weight) {
		best = peer;
  	p = i;
	}
  
  ...
}
```

**3. IP 哈希（IP hash）** 

`ip_hash` 依据发出请求的客户端 IP 的 hash 值来分配服务器，该算法可以保证同 IP 发出的请求映射到同一服务器，或者具有相同 hash 值的不同 IP 映射到同一服务器。

**特点** ：该算法在一定程度上解决了集群部署环境下 Session 不共享的问题。

> Session 不共享问题是说，假设用户已经登录过，此时发出的请求被分配到了 A 服务器，但 A 服务器突然宕机，用户的请求则会被转发到 B 服务器。但由于 Session 不共享，B 无法直接读取用户的登录信息来继续执行其他操作。

实际应用中，我们可以利用 `ip_hash`，将一部分 IP 下的请求转发到运行新版本服务的服务器，另一部分转发到旧版本服务器上，实现灰度发布。再者，如遇到文件过大导致请求超时的情况，也可以利用 `ip_hash` 进行文件的分片上传，它可以保证同客户端发出的文件切片转发到同一服务器，利于其接收切片以及后续的文件合并操作。

**4. 其他算法** 

- URL hash

    `url_hash` 是根据请求的 URL 的 hash 值来分配服务器。该算法的特点是，相同 URL 的请求会分配给固定的服务器，当存在缓存的时候，效率一般较高。然而 Nginx 默认不支持这种负载均衡算法，需要依赖第三方库。

- 最小连接数（Least Connections）

    假设共有**M** 台服务器，当有新的请求出现时，遍历服务器节点列表并选取其中连接数最小的一台服务器来响应当前请求。连接数可以理解为当前处理的请求数。

## 2.3 Nginx 配置

nginx的upstream目前支持的5种方式的分配

### 1、轮询（默认）

每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。

```
upstream backserver { 
server 192.168.0.14; 
server 192.168.0.15; 
}
```

### 2、指定权重

指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。

```
upstream backserver { 
server 192.168.0.14 weight=8; 
server 192.168.0.15 weight=10; 
}
```

### 3、IP绑定 ip_hash

每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。

```
upstream backserver { 
ip_hash; 
server 192.168.0.14:88; 
server 192.168.0.15:80; 
}
```

### 4、fair（第三方）

按后端服务器的响应时间来分配请求，响应时间短的优先分配。

```
upstream backserver { 
server server1; 
server server2; 
fair; 
}
```

### 5、url_hash（第三方）

按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。

```
upstream backserver { 
server squid1:3128; 
server squid2:3128; 
hash $request_uri;
hash_method crc32; 
}
```

在需要使用负载均衡的server中增加

```
proxy_pass http://backserver/; 
upstream backserver{ 
ip_hash; 
server 127.0.0.1:9090 down; (down 表示当前的server暂时不参与负载) 
server 127.0.0.1:8080 weight=2; (weight 默认为1.weight越大，负载的权重就越大) 
server 127.0.0.1:6060; 
server 127.0.0.1:7070 backup; (其它所有的非backup机器down或者忙的时候，请求backup机器) 
}
```

- max_fails：允许请求失败的次数默认为1。当超过最大次数时，返回proxy_next_upstream 模块定义的错误

- fail_timeout：max_fails次失败后，暂停的时间