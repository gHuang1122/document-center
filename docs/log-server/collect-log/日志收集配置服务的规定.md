## 配置服务的规定

1.服务配置文件规定

```yml
#logging
logging:
  config: classpath:logback/logback.xml  
  level:
   com.test: debug
//logging配置是固定的
net:
 file: /app/logs
```

2.logback.xml文件的定义，格式固定

```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration>

	<springProperty scope="context" name="LOG_HOME"
		source="net.file" />
	<include
		resource="org/springframework/boot/logging/logback/base.xml" />

	<appender name="CONSOLE"
		class="ch.qos.logback.core.ConsoleAppender">
		<encoder
			class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
			<pattern>${appname} %d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
		</encoder>
	</appender>

	<!-- 按照每天生成日志文件 -->
	<appender name="FILE"
		class="ch.qos.logback.core.rolling.RollingFileAppender">
		<rollingPolicy
			class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
			<!--日志文件输出的文件名 -->
			<FileNamePattern>${LOG_HOME}/INFO.log.%d{yyyy-MM-dd}.log
			</FileNamePattern>
			<!--日志文件保留天数 -->
			<MaxHistory>30</MaxHistory>
		</rollingPolicy>
		<encoder
			class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
			<!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符 -->
			<pattern>
				{"log_type":"%X{log_type}","self_field":"%X{self_field}","timestamp": "%d{yyyy-MM-dd HH:mm:ss.SSS}","thread": "[%thread]","level":"%-5level" ,"logger":"%logger{50}","msg": "%msg"}%n
			</pattern>
		</encoder>
		<!--日志文件最大的大小 -->
		<triggeringPolicy
			class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">
			<MaxFileSize>10MB</MaxFileSize>
		</triggeringPolicy>
	</appender>
	<root level="INFO">
		<appender-ref ref="FILE" />
		<appender-ref ref="CONSOLE" />
	</root>


</configuration>
```

3.编写docker-compose.yml

```yml
java-demo02:
    image: 'openjdk:8-alpine'
    restart: always
    ports:
      - "28089:8088"
    container_name: 'java-demo02' 
    volumes:
      - ./testDemo2-1.0.0.jar:/app/testDemo2-1.0.0.jar
      - /app/elk/logs/testdemo@@testdemoslave:/app/logs
    command: ['java', '-jar', '/app/testDemo2-1.0.0.jar','--spring.profiles.active=dev']
    depends_on:
      - ys-mysql
    networks:
      - elk
```

- /app/elk/logs/testdemo2_02:/app/logs  指定日志的时候，在物理机器日志目录规定为/app/elk/logs，该目录为所有的服务的日志的根目录。

服务的目录名称定义“微服务的名称@@具体的部署实例取的别名”，**服务名全小写，用"_"下划线来分隔单词**

4.最后日志文件的展示形式，为json格式，key值有：log_type、timestamp、thread、level、logger、msg

| 字段       | 说明                                                 | 是否必填 |
| ---------- | ---------------------------------------------------- | -------- |
| timestamp  | 时间                                                 | 是       |
| thread     | 线程                                                 | 否       |
| level      | 级别（INFO、DEBUG、ERROR）                           | 是       |
| logger     | 类                                                   | 否       |
| msg        | 信息                                                 | 是       |
| log_type   | 类型                                                 | 否       |
| self_field | 自定义类型（字符串，该字段分词，该字段支持全文检索） | 否       |

demo如下：

```json
{"log_type":"错误日志","timestamp": "2021-03-15 08:55:43.084","thread": "[http-nio-8088-exec-2]","level":"DEBUG" ,"logger":"com.test.demo.dao.TravelDao.selectById","msg": "==>  Preparing: SELECT id,group_name,start,destination,content FROM travel WHERE id=? "}
{"log_type":"正确日志","timestamp": "2021-03-15 08:55:43.085","thread": "[http-nio-8088-exec-2]","level":"DEBUG" ,"logger":"com.test.demo.dao.TravelDao.selectById","msg": "==> Parameters: 1364469721742798850(String)"}
{"log_type":"告警日志","timestamp": "2021-03-15 08:55:43.088","thread": "[http-nio-8088-exec-2]","level":"DEBUG" ,"logger":"com.test.demo.dao.TravelDao.selectById","msg": "<==      Total: 0"}
```

同理，也可以自己增加其他字段，springboot 工程建议如下方式:

```
MDC.put("log_type", "错误日志");
```

```java

@GetMapping(value = "/{id}")
	@ApiOperation(value = "查询", notes = "查询")
	public Object getById(@Validated @PathVariable String id) {
	    MDC.put("camera_id", "1306506715964903425");
		return travelService.getById(id);
}
```

同时修改

添加logtype的键值对到对应的配置文件中，如果是kafka传递日志，则直接添加到消息中字段即可

```
<pattern>
				{"log_type":"%X{log_type}","timestamp": "%d{yyyy-MM-dd HH:mm:ss.SSS}","thread": "[%thread]","level":"%-5level" ,"logger":"%logger{50}","msg": "%msg"}%n
			</pattern>
```

5.如果是利用kafka来传递实时的消息，kafka 消息的topic 是server-logs

```
{"appname":"test_demo3","server_instance":"003","log_type":"错误日志","timestamp": "2021-03-15 08:55:43.088","thread": "[http-nio-8088-exec-2]","level":"DEBUG" ,"logger":"com.test.demo.dao.TravelDao.selectById","msg": "<==      Total: 0"}
```

**"appname":"test_demo3","server_instance":"003"**,因为不是通过外部文件来命名服务和实例，所以这两个字段是必须要传的，一个是服务名，一个是实例名，其余的字段可以有可以不写，消息用msg来标示

6.查看日志地址：

[kibana界面]: http://172.18.8.172:5601/app/kibana#/discover?_g=()&amp;_a=(columns:!(_source),index:&#39;27c5d800-87c0-11eb-81bf-33024443ec01&#39;,interval:auto,query:(language:kuery,query:&#39;&#39;),sort:!(&#39;@timestamp&#39;,desc))

